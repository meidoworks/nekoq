gnatsd:
bc84847123e678f0051ff4e082515a2c6421823e
1. server keeps subscriber list(goroutine safe)
2. pub -> match list -> write to client -> delayed flush

RocketMQ:
//TODO

iris:
iris network
communication model:
broadcast -> message to group
Request/Reply -> to a group to balance like RPC
Publish/Subscribe -> topic to send/receive msg like MQ
Tunnel -> generally like TCP but distributed
//TODO

nsq:
63596a8693e7d65d79a27d8af5cdb1acf67cca6f
1. goroutine c: pub -> topic queue include memchan & backendChan (select)
2. goroutine t: topic -> from memchan & backendChan (select) to all channels
3. goroutine ch: channel -> Different type of worker - inflight/deffered/etc. -> to clientMsgChan
4. goroutine c: get msg from clientMsgChan and write
1 & 4 are in the same loop (select)
//TODO persistent

kafka:
//TODO

activemq:
//TODO

rabbitmq:
//TODO

moonmq:
1. queue: a loop for connection, pubsub, etc.
2. store & ack: save to store -> deliver -> ack -> delete from store
3. store: mem, redis, etc.

surgemq:
1. linked list to store topics
2. RWLock for topic CRUD
3. client session for client related data storage
4. client conn write lock
5. ring buffer for read/write
6. goroutines to read / send -> to / from ring buffer, conn goroutines
7. pub -> match -> pub in one goroutine, process goroutine
8. decode/encode simulation of enum
9. qos implements - ack queue -> acked -> process this queue
10. api for admin
11. rate limit


go model:
client -> chan -> topic & queue container -> chan -> client

java model:
client -> thread pool(queue) -> topic & queue container -> channel(queued) -> client


topic:
1. generate msg id
2. defines a group to deliver
3. should connect to queue

subsription:
1. type sub - receive messages - no queue binded
2. guarantee order for every subscription
3. should connect to queue

publish action:
1. using topic

queue:
1. infrastructure of delivery
2. guarantee consistence

additional support:
1. qos
2. ack / batch support / tcp like ack supporting batch
3. repeated consume (subscribe from index)
4. msg ttl & operation timeout
5. chunked mode - upload + send item id
6. frontend interface module
7. use dual-topic to emulate client id and response based tranport like rpc and so on
8. delete on consume flag for kafka like msg consuming
9. shutdown / close
10. store manager for metadata(topic, queue, etc.) preload
11. timeout: back to queue
12. delay: available in queue
13. expire: auto delete time
14. Messages per Get: # of messages per get op



pattern:
1. close pattern: select { case <- closeSignal: XXX   case -> sendCh: YYY }





encoding package:
1. 4 bytes alignment
2. version check
3. modify []byte api
4. field index check and match
